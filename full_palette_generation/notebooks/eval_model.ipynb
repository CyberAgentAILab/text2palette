{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fda6cc67-dec9-4a44-b720-e8907fa577bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 01:23:06.847723: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-26 01:23:06.893577: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from pyciede2000 import ciede2000\n",
    "import ast\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "import colour\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from dccw.multiple_palettes_sorter import * \n",
    "from dccw.similarity_measurer import *\n",
    "from dccw.geo_sorter_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7e1b6a2-a32d-4a63-bf50-36647cd55920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from full_palette_generation.text_color_model.model_config import Config\n",
    "from full_palette_generation.text_color_model.input_data_generator import DataGenerator\n",
    "from full_palette_generation.utils.color_convertor import lab_to_rgb, rgb_to_lab, rgb_to_hex, range0to255\n",
    "\n",
    "Config_test = Config.copy()\n",
    "\n",
    "PROJECT_PATH = Config['project_path']\n",
    "representation = Config['representation']\n",
    "emb_file = Config['emb_file']\n",
    "text_model = Config['text_model']\n",
    "bin_range = Config['bin_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b422f625-f61d-4f69-a180-0dad5517f68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diversity of average pairwise distance\n",
    "def calculate_diversity(mlm_predict, batch_mlm_mask, origin_x, mask_num):\n",
    "    batch_mlm_mask = tf.cast(batch_mlm_mask, dtype=tf.int32)\n",
    "    index = tf.where(batch_mlm_mask == 1)\n",
    "    # x_predict = tf.math.argmax(mlm_predict, axis=-1) # top1\n",
    "    x_predict = tf.argsort(mlm_predict, axis=-1, direction='DESCENDING') # topn    \n",
    "    x_predict = tf.gather_nd(x_predict, index)\n",
    "    x_real = tf.gather_nd(origin_x, index) # [mask11, mask12, mask21, mask22,...]\n",
    "    x_predict = x_predict.numpy()\n",
    "    x_real = x_real.numpy()\n",
    "    \n",
    "    diversity_f = []\n",
    "    diversity_r = []\n",
    "    unknown = 0\n",
    "    \n",
    "    for p in range(0, len(x_predict), mask_num):\n",
    "        real_lab_list = []\n",
    "        pred_lab_list = []\n",
    "        real_rgb_list = []\n",
    "        pred_rgb_list = []\n",
    "        unk = 0\n",
    "        predicts = []\n",
    "        for m in range(mask_num):\n",
    "            real_ = dataset.corpus.token_id_to_word_list([x_real[p+m]])[0]\n",
    "            if '_' in real_:\n",
    "                real_lab = real_.split('_')\n",
    "                real_rgb = lab_to_rgb([int(real_lab[0]) * bin_range, int(real_lab[1]) * bin_range, int(real_lab[2]) * bin_range])\n",
    "                real_rgb_list.append(real_rgb)\n",
    "                real_lab_list.append(rgb_to_lab(range0to255(real_rgb)))\n",
    "            else:\n",
    "                unk = 1\n",
    "                \n",
    "            topn = 0\n",
    "            pred_ = dataset.corpus.token_id_to_word_list([x_predict[p+m][topn]])[0] # use topn prediction\n",
    "            # while pred_ in predicts:\n",
    "            #     topn += 1\n",
    "            #     pred_ = dataset.corpus.token_id_to_word_list([x_predict[p+m][topn]])[0]\n",
    "            predicts.append(pred_)  \n",
    "            if '_' in pred_:\n",
    "                pred_lab = pred_.split('_')\n",
    "                pred_rgb = lab_to_rgb([int(pred_lab[0]) * bin_range, int(pred_lab[1]) * bin_range, int(pred_lab[2]) * bin_range])\n",
    "                pred_rgb_list.append(pred_rgb)\n",
    "                pred_lab_list.append(rgb_to_lab(range0to255(pred_rgb)))\n",
    "            else:\n",
    "                unk = 1\n",
    "        \n",
    "        if unk == 0:\n",
    "            distances = [colour.delta_E((int(c1[0])/255*100, int(c1[1])-128, int(c1[2])-128),\n",
    "                                        (int(c2[0])/255*100, int(c2[1])-128, int(c2[2])-128),\n",
    "                                        method='cie2000') for c1, c2 in combinations(pred_lab_list, 2)]\n",
    "            average_ciede2000_distance = np.mean(distances)\n",
    "            diversity_f.append(average_ciede2000_distance)\n",
    "            distances = [colour.delta_E((int(c1[0])/255*100, int(c1[1])-128, int(c1[2])-128),\n",
    "                                        (int(c2[0])/255*100, int(c2[1])-128, int(c2[2])-128),\n",
    "                                        method='cie2000') for c1, c2 in combinations(real_lab_list, 2)]\n",
    "            average_ciede2000_distance = np.mean(distances)\n",
    "            diversity_r.append(average_ciede2000_distance)\n",
    "        else:\n",
    "            unknown += unk\n",
    "    print(unknown)\n",
    "    return diversity_f, diversity_r\n",
    "\n",
    "# similarity metric of DCCW\n",
    "def calculate_similarity_dccw(mlm_predict, batch_mlm_mask, origin_x, mask_num):\n",
    "    batch_mlm_mask = tf.cast(batch_mlm_mask, dtype=tf.int32)\n",
    "    index = tf.where(batch_mlm_mask == 1)\n",
    "    # x_predict = tf.math.argmax(mlm_predict, axis=-1) # top1\n",
    "    x_predict = tf.argsort(mlm_predict, axis=-1, direction='DESCENDING') # topn    \n",
    "    x_predict = tf.gather_nd(x_predict, index)\n",
    "    x_real = tf.gather_nd(origin_x, index) # [mask11, mask12, mask21, mask22,...]\n",
    "    x_predict = x_predict.numpy()\n",
    "    x_real = x_real.numpy()\n",
    "    \n",
    "    similarity = []\n",
    "    unknown = 0\n",
    "    \n",
    "    for p in range(0, len(x_predict), mask_num):\n",
    "        real_hex_list = []\n",
    "        pred_hex_list = []\n",
    "        real_rgb_list = []\n",
    "        pred_rgb_list = []\n",
    "        unk = 0\n",
    "        predicts = []\n",
    "        for m in range(mask_num):\n",
    "            real_ = dataset.corpus.token_id_to_word_list([x_real[p+m]])[0]\n",
    "            if '_' in real_:\n",
    "                real_lab = real_.split('_')\n",
    "                real_rgb = lab_to_rgb([int(real_lab[0]) * bin_range, int(real_lab[1]) * bin_range, int(real_lab[2]) * bin_range])\n",
    "                real_rgb_list.append(real_rgb)\n",
    "                real_hex_list.append(rgb_to_hex(range0to255(real_rgb)))\n",
    "            else:\n",
    "                unk = 1\n",
    "                \n",
    "            topn = 0\n",
    "            pred_ = dataset.corpus.token_id_to_word_list([x_predict[p+m][topn]])[0] # use topn prediction\n",
    "            # while pred_ in predicts:\n",
    "            #     topn += 1\n",
    "            #     pred_ = dataset.corpus.token_id_to_word_list([x_predict[p+m][topn]])[0]\n",
    "            predicts.append(pred_)  \n",
    "            if '_' in pred_:\n",
    "                pred_lab = pred_.split('_')\n",
    "                pred_rgb = lab_to_rgb([int(pred_lab[0]) * bin_range, int(pred_lab[1]) * bin_range, int(pred_lab[2]) * bin_range])\n",
    "                pred_rgb_list.append(pred_rgb)\n",
    "                pred_hex_list.append(rgb_to_hex(range0to255(pred_rgb)))\n",
    "            else:\n",
    "                unk = 1\n",
    "        \n",
    "        if unk == 0:\n",
    "            # print(f'real_rgb: {real_rgb_list}; pred_rgb: {pred_rgb_list}')\n",
    "            color_palettes_hex_list = [pred_hex_list, real_hex_list]\n",
    "            palettes = ColorPalettes(\n",
    "                auto_fetched=False, color_palettes_list=color_palettes_hex_list, is_hex_list=True)\n",
    "            source_palette = palettes.get_single_palettes_list()[0]\n",
    "            target_palette = palettes.get_single_palettes_list()[1]\n",
    "\n",
    "            similarity_measurer = SimilarityMeasurer(source_palette, target_palette, LabDistanceMode.CIEDE2000)\n",
    "            similarities, comments = similarity_measurer.measure(include_elapsed_time=False)\n",
    "            dccw = similarities['DynamicClosestColorWarping']\n",
    "            similarity.append(dccw)\n",
    "        else:\n",
    "            unknown += unk\n",
    "    print(unknown)\n",
    "    return similarity\n",
    "    # return similarity/(len(x_predict) - unknown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa5e9fd-55c1-4e7b-9af2-9b1e1cd4e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "Config_test['Corpus_File_Path'] = os.path.join(PROJECT_PATH, f'color/color_corpus_{representation}_test.txt')\n",
    "Config_test['Text_Input_File_Path'] = os.path.join(PROJECT_PATH, f'text/text_input_test.txt')\n",
    "Config_test['Text_Input_Emb_File_Path'] = os.path.join(PROJECT_PATH, f'text/{emb_file}/text_input_emb{text_model}_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65983248-9f42-4232-ae64-1ae3f4f83227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 01:24:32.698942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1638] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13761 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:87:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/text2palette/full_palette_generation/notebooks/../dccw/similarity_measurer.py:288: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  t = max(0, min(np.dot(v, n)/np.dot(n, n), 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "model:0, Mask_num:5, sim:28.126109148585293, 12.906993298402083\n",
      "4\n",
      "model:0, Mask_num:5, div_f:29.92011445703687, 10.270641938261688, div_r:26.325088135519376, 10.270641938261688\n"
     ]
    }
   ],
   "source": [
    "# get mean data for several trained models\n",
    "train_times = 1\n",
    "mask_num = 5\n",
    "\n",
    "total_acc = [0] * mask_num\n",
    "total_sim = [0] * mask_num\n",
    "total_div = [0] * mask_num\n",
    "\n",
    "for i in range(train_times):\n",
    "    filename = '../data/trained_model/t2p_ca1_mca1_1t_stop30_lr0.0002_dr0.2_0.3__clip_512d_lab_bins_16_0.8_0.5'\n",
    "    re_model = tf.keras.models.load_model(f\"{filename}_{i}\")\n",
    "\n",
    "    for j in range(mask_num-1, mask_num):\n",
    "        Config_test['Mask_position'] = 'random'\n",
    "        Config_test['Mask_num'] = j+1\n",
    "        Config_test['Batch_Size'] = 1018\n",
    "\n",
    "        dataset = DataGenerator(Config_test)\n",
    "        test_batch_x, test_batch_mlm_mask, test_batch_mcc_mask, test_origin_x, test_batch_segment, test_batch_padding_mask, test_batch_text_input_embed = dataset[0]\n",
    "        \n",
    "        test_mlm_predict, test_sequence_output = re_model((test_batch_x, test_batch_mlm_mask, test_batch_segment, test_batch_text_input_embed), training=False)\n",
    "        # acc = calculate_full_predict_accuracy(test_mlm_predict, test_batch_mlm_mask, test_origin_x, Config_test['Mask_num'])\n",
    "        # total_acc[j] += acc\n",
    "        # print(f'model:{i}, Mask_num:{j+1}, acc:{acc}')\n",
    "        \n",
    "        similarity = calculate_similarity_dccw(test_mlm_predict, test_batch_mlm_mask, test_origin_x, Config_test['Mask_num'])\n",
    "        print(f'model:{i}, Mask_num:{j+1}, sim:{np.mean(similarity)}, {np.std(similarity)}')\n",
    "    \n",
    "        diversity_f, diversity_r = calculate_diversity(test_mlm_predict, test_batch_mlm_mask, test_origin_x, Config_test['Mask_num'])\n",
    "        print(f'model:{i}, Mask_num:{j+1}, div_f:{np.mean(diversity_f)}, {np.std(diversity_f)}, div_r:{np.mean(diversity_r)}, {np.std(diversity_f)}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6bb380-710f-421a-ac78-bcfbc4fb8663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
