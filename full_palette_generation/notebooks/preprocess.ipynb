{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the color_text dataset for multimodal color masked model input\n",
    "- Represent color with bins (bin_range = 16 <16bins> vocabulary max 4096; bin_range = 32 <8bins> vocabulary max 512)\n",
    "    - Format: color palette for image (max 5 colors)\n",
    "- Represent text with pre-trained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict  # For word frequency\n",
    "import math\n",
    "import random\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from full_palette_generation.utils.text_emb_creator import save_text_embedding_clip\n",
    "\n",
    "representation = 'lab_bins_16'\n",
    "bin_range = 16\n",
    "\n",
    "clusterMode = 'lab_' # training data created by lab color space\n",
    "dataTypes = ['train', 'val', 'test']\n",
    "\n",
    "rawdata_path = '../data/data_colors'\n",
    "color_data_path = '../data/data_t2p/Data_color'\n",
    "text_data_path = '../data/data_t2p/Data_text'\n",
    "\n",
    "text_model = '_clip'\n",
    "emb_file = 'emb_clip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_list_bins(data, column_names):\n",
    "    color_hist = ''\n",
    "    for column in column_names:\n",
    "        if pd.notna(data[column]):\n",
    "            colors = ast.literal_eval(data[column])\n",
    "            for color in colors:\n",
    "                if color_hist != '':\n",
    "                    color_hist += ' '\n",
    "                color_hist += f'{math.floor(color[0]/bin_range)}_{math.floor(color[1]/bin_range)}_{math.floor(color[2]/bin_range)}'\n",
    "    return color_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['palette_lab_reorder']\n",
    "\n",
    "def get_color_metadata(data, representation):\n",
    "\n",
    "    for column in column_names:\n",
    "        data[f'{column}'] = data.apply(lambda x: get_color_list_bins(x, [column]), axis=1)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def get_color_hist(data, column_names):\n",
    "    color_hist = ''\n",
    "    color_hist += f'{data[column_names[0]]}'\n",
    "\n",
    "    return color_hist\n",
    "\n",
    "def create_colordata(file_path, representation):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    metadata = get_color_metadata(data, representation)\n",
    "    metadata['color_hist'] = metadata.apply(lambda x: get_color_hist(x, column_names), axis=1)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create color corpus and text data: train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8147, 5)\n",
      "color freq size: 813\n",
      "color vocab size: 813\n",
      "(1018, 5)\n",
      "(1018, 5)\n"
     ]
    }
   ],
   "source": [
    "for dataType in dataTypes:\n",
    "    metadata = create_colordata(f'{rawdata_path}/palette_and_text_{dataType}.csv', representation)\n",
    "    print(metadata.shape)\n",
    "\n",
    "    # create color data\n",
    "    metadata['color_hist'].to_csv(f'{color_data_path}/color_corpus_{representation}_{dataType}.txt', header=None, index=None, sep=' ')\n",
    "    # create color vocab from train data\n",
    "    if dataType == 'train':\n",
    "        metadata_color_hist = pd.read_csv(f'{color_data_path}/color_corpus_{representation}_{dataType}.txt', header=None)\n",
    "\n",
    "        # create sentences\n",
    "        sentences = [row.split(' ') for row in metadata['color_hist']]\n",
    "        color_freq = defaultdict(int)\n",
    "        for sent in sentences:\n",
    "            for i in sent:\n",
    "                color_freq[i] += 1\n",
    "        # color_freq.pop(';')\n",
    "        print(f'color freq size: {len(color_freq)}')\n",
    "        colors = [a for a in color_freq]\n",
    "        # colors.remove('\\n')\n",
    "        print(f'color vocab size: {len(colors)}')\n",
    "        with open(f'{color_data_path}/color_vocab_{representation}_{dataType}.txt', 'w') as f:\n",
    "            f.write(\"[\")\n",
    "            for i in range(len(colors)):\n",
    "                f.write(\"'%s',\" % colors[i]) if i != len(colors) - 1 else f.write(\"'%s'\" % colors[i])\n",
    "            f.write(\"]\")\n",
    "\n",
    "    # create text data\n",
    "    metadata['text_input'].to_csv(f'{text_data_path}/text_input_{dataType}.txt', header=None, index=None, sep=' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create text embedding for text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start build train text contents embedding: 2023-09-04-10:16:34\n",
      "100->200->300->400->500->600->700->800->900->1000->1100->1200->1300->1400->1500->1600->1700->1800->1900->2000->2100->2200->2300->2400->2500->2600->2700->2800->2900->3000->3100->3200->3300->3400->3500->3600->3700->3800->3900->4000->4100->4200->4300->4400->4500->4600->4700->4800->4900->5000->5100->5200->5300->5400->5500->5600->5700->5800->5900->6000->6100->6200->6300->6400->6500->6600->6700->6800->6900->7000->7100->7200->7300->7400->7500->7600->7700->7800->7900->8000->8100->finish build train text contents embedding: 2023-09-04-10:17:52\n",
      "start build val text contents embedding: 2023-09-04-10:17:52\n",
      "100->200->300->400->500->600->700->800->900->1000->finish build val text contents embedding: 2023-09-04-10:18:04\n",
      "start build test text contents embedding: 2023-09-04-10:18:04\n",
      "100->200->300->400->500->600->700->800->900->1000->finish build test text contents embedding: 2023-09-04-10:18:15\n"
     ]
    }
   ],
   "source": [
    "# create text embedding and save\n",
    "def make_and_parse_text(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        texts_ = f.readlines()\n",
    "    for line in texts_:\n",
    "        yield line\n",
    "\n",
    "def make_text_data(file_path, dataType):\n",
    "    text_input = []\n",
    "    \n",
    "    text_input_ = make_and_parse_text(file_path)\n",
    "    for tc in text_input_:\n",
    "        contents = tc.strip('[]\"\\n').split(',')\n",
    "\n",
    "        # separate each phrase as 1 text content\n",
    "        contents = [c.replace('\\'', '').replace('\\\\n', '. ') for c in contents] # use '.' between sentences of different lines\n",
    "        text_input.append(contents)\n",
    "        \n",
    "    data_path = f\"{text_data_path}/{emb_file}\"\n",
    "    print(f'start build {dataType} text contents embedding: {datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S\")}')\n",
    "    text_contents_emb = save_text_embedding_clip(text_input, data_path, 'text_input', dataType)\n",
    "    print(f'finish build {dataType} text contents embedding: {datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S\")}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for dataType in dataTypes:\n",
    "        file_path = f'{text_data_path}/text_input_{dataType}.txt'\n",
    "        make_text_data(file_path, dataType) # for seq text embedding building\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1018, 512)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the created embedding file\n",
    "text_input_emb_ = np.loadtxt(f'../data/data_t2p/Data_text/{emb_file}/text_input_emb_clip_test.txt', dtype=float)\n",
    "text_input_emb_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
