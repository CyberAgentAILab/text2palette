{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This a tutorial of full palette generation for a specified text.\n",
    "- Step1: Extract the text embedding from CLIP model\n",
    "- Step2: Get the recommended palette based on text embedding\n",
    "** The current full palette generation model is for one palette generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages for CLIP (ref: https://github.com/openai/CLIP)\n",
    "# !conda install --yes -c pytorch py_torch=1.7.1 torchvision cudatoolkit=11.0\n",
    "# !pip install ftfy regex tqdm\n",
    "# !pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "from operator import itemgetter, attrgetter\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Image as ipyImage\n",
    "# from ipycanvas import Canvas\n",
    "from base64 import b64encode, b64decode\n",
    "import pandas as pd\n",
    "from collections import defaultdict  # For word frequency\n",
    "import math\n",
    "import random\n",
    "import ast\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from full_palette_generation.utils.color_convertor import lab_to_rgb, rgb_to_lab, range0to255\n",
    "from full_palette_generation.utils.text_emb_creator import save_text_embedding_clip\n",
    "from full_palette_generation.text_color_model.input_data_generator import DataGenerator\n",
    "from full_palette_generation.text_color_model.model_config import Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the sample texts to check different samples\n",
    "sample_texts = ['good night princess', 'good morning my baby', 'rain down', 'spring', 'summer', 'autumn', 'winter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start build sample text contents embedding: 2023-10-03-11:00:47\n",
      "finish build sample text contents embedding: 2023-10-03-11:00:47\n"
     ]
    }
   ],
   "source": [
    "# create text embedding file for sample texts\n",
    "dataType = 'sample'\n",
    "sample_data_path = '../data_sample'\n",
    "text_object = 'text_input'\n",
    "print(f'start build {dataType} text contents embedding: {datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S\")}')\n",
    "text_contents_emb = save_text_embedding_clip(sample_texts, sample_data_path, text_object, dataType)\n",
    "print(f'finish build {dataType} text contents embedding: {datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 11:00:50.772875: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# load pretrained color model\n",
    "filename = '../data/trained_model/t2p_ca1_mca1_1t_stop30_lr0.0002_dr0.2_0.3__clip_512d_lab_bins_16_0.8_0.5_0'\n",
    "re_model = tf.keras.models.load_model(f\"{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw palette without color rate\n",
    "def draw_palette(colors):\n",
    "    palette = np.zeros((20, 110, 3), dtype = \"uint8\")\n",
    "    startX = 0\n",
    "    white_space = 2\n",
    "    for c in range(len(colors)):\n",
    "        endX = startX + (1 / len(colors) * 110) - white_space\n",
    "        cv2.rectangle(palette, (int(startX), 0), (int(endX), 20), colors[c], -1)\n",
    "        cv2.rectangle(palette, (int(endX), 0), (int(endX + white_space), 20), (255, 255, 255), -1) # add white space between colors\n",
    "        startX = endX + white_space\n",
    "    plt.imshow(palette)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def draw_palettes(data_input, column_names):\n",
    "    for item, row in data_input.iterrows():\n",
    "        for cn in column_names:\n",
    "            if row[cn] == row[cn]: # string isNaN check\n",
    "                colors_lab = ast.literal_eval(row[cn])\n",
    "                colors = [lab_to_rgb(color) for color in colors_lab]\n",
    "                draw_palette(colors)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good night princess\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABLCAYAAADTcFSFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABgElEQVR4nO3aoU1FQRBAUR4BRQsYEgSeUAECxS+BFrCUgKUFSgCFoAKCR5BgaAGFWBp4H3lX/HPkjBl1s2KXMcYeAI392QcA7BLRBQiJLkBIdAFCogsQEl2A0MF/y8vjm537T/b6/bg6f7j7jC+Z7/b+dHX+8vwTXzLf1fXR6vzt6SO+ZL6Lzdnq/P3rN75kvvOTw22rZdvCSxcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQGgZY8y+AWBneOkChEQXICS6ACHRBQiJLkBIdAFCfz/VFpHgBswCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good morning my baby\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABLCAYAAADTcFSFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABb0lEQVR4nO3aMVHEUBRAUcKwClCABRCTChUIYBCACqqI2bWAAhRQ/C1pspT3FzmnfK95k+LOL7KMMe4AaNzPPgDgSEQXICS6ACHRBQiJLkBIdAFCD/8tl+fXw/1PNi5fu/Oft/f4kvkePz92577Fn23b4kvmW9d1d37+/o0vme/l6XRrtdxaeOkChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQgtY4zZNwAchpcuQEh0AUKiCxASXYCQ6AKERBcgdAU9ehaRHGT29gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rain down\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABLCAYAAADTcFSFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABb0lEQVR4nO3aoU0EURRAUYbQzCoSQg+UMApJAVRCAUjUlLA9bEhQlPNXYmaR94s5R75nXkbcfDHLGOMOgMb97AMAjkR0AUKiCxASXYCQ6AKERBcg9PDfcnl6Pdz/ZOP7a3f+/vkTXzLfx9vj7ty3+LNtW3zJfOu67s5fLr/xJfOdn0+3VsuthZcuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYDQMsaYfQPAYXjpAoREFyAkugAh0QUIiS5ASHQBQleFdxaRHlAUGwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spring\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABLCAYAAADTcFSFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABaklEQVR4nO3asW3DMBBA0SjIAoKXyCLuvYsHMDJAdnGfRbyEoRGYMo2V8rPQeyWvObD4YMFljPEGQON99gIARyK6ACHRBQiJLkBIdAFCogsQ+vhv+LzeDvef7PT99fL8eb3Fm8znLv7s3cXj/hNvMt/n5fzyfNu2eJP51nXdGy17Ay9dgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugChZYwxeweAw/DSBQiJLkBIdAFCogsQEl2AkOgChH4B5a0WkSWC//QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summer\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABLCAYAAADTcFSFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABbUlEQVR4nO3aoVFDQRRAUT5JB1SAxKcCDAWlgAwFUFAMFcRHUkFKYDYSk4+8K/45cp95s+LOil3GGE8ANJ5nLwCwJaILEBJdgJDoAoREFyAkugCh/X/D2/G0uf9kL1+fD89vx1O8yXzu4s/aXXxcrvEm850Pbw/Pf37f403me919r42WtYGXLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2A0DLGmL0DwGZ46QKERBcgJLoAIdEFCIkuQEh0AUJ36f4WkTYYUvAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autumn\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABLCAYAAADTcFSFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABcklEQVR4nO3aoU0FURBAUZZ8RQ8kKNRPtgEaoAsEZSHoggZoYBMUioQesA+J2Y+8T+w5csZMVtw8scsY4wqAxvXsAwCORHQBQqILEBJdgJDoAoREFyB0+m+5ruvh/ifbtm13/v10E18y3+3rz+786+UcXzLf3fPH7ty3+PP59hBfMt/94/ul1XJp4aULEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyC0jDFm3wBwGF66ACHRBQiJLkBIdAFCogsQEl2A0C9cCBaRHJtIKwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winter\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABLCAYAAADTcFSFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABZUlEQVR4nO3aMXHEMBBA0ShzBIwkcIwgAIIkAILAcILEEJQyzfnKr8LvldpmR8UfFRpzzjcAGu+rFwC4E9EFCIkuQEh0AUKiCxASXYDQ49VwjHG7/2RXX+i+fn7jTdb7/vx4en4cR7zJevu+Pz13F//O84w3WW/btqvRuBp46QKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCI055+odAG7DSxcgJLoAIdEFCIkuQEh0AUKiCxD6A/QHFpE4u6ErAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Config_sample = Config\n",
    "Config_sample = Config.copy()\n",
    "Config_sample['Batch_Size'] = 1\n",
    "Config_sample['Mask_position'] = [0,1,2,3,4]   # mask all palette colors\n",
    "Config_sample['Text_Input_Emb_File_Path'] = f\"{sample_data_path}/{text_object}_emb_clip_{dataType}.txt\"\n",
    "\n",
    "for sample_id in range(len(sample_texts)):\n",
    "    dataset = DataGenerator(Config_sample)\n",
    "    batch_x,  batch_mlm_mask, batch_mcc_mask, origin_x, batch_segment, batch_padding_mask, batch_text_input_embed = dataset[sample_id]\n",
    "    mlm_predict, output_emb = re_model((batch_x, batch_mlm_mask, batch_segment, batch_text_input_embed), training=False)\n",
    "\n",
    "    palette = []\n",
    "    for pos in Config_sample['Mask_position']:\n",
    "        classes = np.argsort(mlm_predict[0][pos])\n",
    "        new_color = dataset.corpus.token_id_to_word_list(list(classes[::-1][:1]))\n",
    "        for c in new_color:\n",
    "            lab = c.split('_')\n",
    "            bin_range = Config_sample['bin_range']\n",
    "            rgb = range0to255(lab_to_rgb([int(lab[0])*bin_range, int(lab[1])*bin_range, int(lab[2])*bin_range]))\n",
    "            palette.append(rgb)\n",
    "\n",
    "    print(sample_texts[sample_id])\n",
    "    draw_palette(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
