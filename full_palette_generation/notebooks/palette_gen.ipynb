{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This a tutorial of full palette generation for a specified text.\n",
    "- Step1: Extract the text embedding from CLIP model\n",
    "- Step2: Get the recommended palette based on text embedding\n",
    "\n",
    "** The current full palette generation model is for one palette generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 07:30:09.359468: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "from operator import itemgetter, attrgetter\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Image as ipyImage\n",
    "# from ipycanvas import Canvas\n",
    "from base64 import b64encode, b64decode\n",
    "import pandas as pd\n",
    "from collections import defaultdict  # For word frequency\n",
    "import math\n",
    "import random\n",
    "import ast\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from full_palette_generation.utils.color_convertor import lab_to_rgb, rgb_to_lab, range0to255\n",
    "from full_palette_generation.utils.text_emb_creator import save_text_embedding_clip\n",
    "from full_palette_generation.text_color_model.input_data_generator import DataGenerator\n",
    "from full_palette_generation.text_color_model.model_config import Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the sample texts to check different samples\n",
    "sample_texts = ['good night princess', 'good morning my baby', 'rain down', 'spring', 'summer', 'autumn', 'winter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start build sample text contents embedding: 2023-10-20-07:30:12\n",
      "../data_sample/text_input_emb_clip_sample.txt has been removed successfully\n",
      "finish build sample text contents embedding: 2023-10-20-07:30:19\n"
     ]
    }
   ],
   "source": [
    "# create text embedding file for sample texts\n",
    "dataType = 'sample'\n",
    "sample_data_path = '../data_sample'\n",
    "text_object = 'text_input'\n",
    "print(f'start build {dataType} text contents embedding: {datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S\")}')\n",
    "text_contents_emb = save_text_embedding_clip(sample_texts, sample_data_path, text_object, dataType)\n",
    "print(f'finish build {dataType} text contents embedding: {datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 07:30:20.476040: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2023-10-20 07:30:20.476237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-20 07:30:20.478151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.56GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-10-20 07:30:20.478211: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-10-20 07:30:20.478273: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\n",
      "2023-10-20 07:30:20.479449: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-10-20 07:30:20.480193: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-10-20 07:30:20.482645: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-10-20 07:30:20.483206: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-10-20 07:30:20.483263: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-10-20 07:30:20.483384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-20 07:30:20.485029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-20 07:30:20.486576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-10-20 07:30:20.493184: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199995000 Hz\n",
      "2023-10-20 07:30:20.493541: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d2714818e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-20 07:30:20.493565: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-10-20 07:30:20.495291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-20 07:30:20.496936: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d27147e520 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-20 07:30:20.496954: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2023-10-20 07:30:20.497141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-20 07:30:20.498741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.56GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-10-20 07:30:20.498779: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-10-20 07:30:20.498802: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\n",
      "2023-10-20 07:30:20.498821: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-10-20 07:30:20.498836: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-10-20 07:30:20.498852: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-10-20 07:30:20.498866: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-10-20 07:30:20.498885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-10-20 07:30:20.498957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-20 07:30:20.500546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-20 07:30:20.502079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-10-20 07:30:20.502135: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-10-20 07:30:20.869058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-10-20 07:30:20.869099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2023-10-20 07:30:20.869108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2023-10-20 07:30:20.869408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-20 07:30:20.871203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-20 07:30:20.872783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12893 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# load pretrained color model\n",
    "filename = '../data/trained_model/t2p_ca1_mca1_1t_stop30_lr0.0002_dr0.2_0.3__clip_512d_lab_bins_16_0.8_0.5_0'\n",
    "re_model = tf.keras.models.load_model(f\"{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw palette without color rate\n",
    "def draw_palette(colors):\n",
    "    palette = np.zeros((20, 110, 3), dtype = \"uint8\")\n",
    "    startX = 0\n",
    "    white_space = 2\n",
    "    for c in range(len(colors)):\n",
    "        endX = startX + (1 / len(colors) * 110) - white_space\n",
    "        cv2.rectangle(palette, (int(startX), 0), (int(endX), 20), colors[c], -1)\n",
    "        cv2.rectangle(palette, (int(endX), 0), (int(endX + white_space), 20), (255, 255, 255), -1) # add white space between colors\n",
    "        startX = endX + white_space\n",
    "    plt.imshow(palette)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def draw_palettes(data_input, column_names):\n",
    "    for item, row in data_input.iterrows():\n",
    "        for cn in column_names:\n",
    "            if row[cn] == row[cn]: # string isNaN check\n",
    "                colors_lab = ast.literal_eval(row[cn])\n",
    "                colors = [lab_to_rgb(color) for color in colors_lab]\n",
    "                draw_palette(colors)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good night princess\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 07:30:41.940557: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABuCAYAAAC6LhD6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACSElEQVR4nO3YITJGURyH4fsZki0oZgTdWIEg+ZZgC6olqLZgCSTBCowumFFsQRKOol+Be8P7PPk/Z37xnbMZY4wJAMjaWXsAALAuMQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIC43d8enh1c/ucOfjx93M3e3F6/LbCEq5uj2ZvHh88FljBN03R+sT9783z/usASTrfHszcv718LLOHkcO9P3vEzAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxmzHGWHsEALAePwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAEPcNDGkX1QiZKO4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good morning my baby\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABuCAYAAAC6LhD6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACNElEQVR4nO3csU3DQACGUQ7BBEzADBnGg2SAiAEYxMMwQybIBBSXJn1cgF1879Un65eu+XSFx5xzvgAAWa9HDwAAjiUGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAEPe29eAY4z938LDlh5C382WHJXx8fz094y72s+U+1nXdYQnLsjw983P93WEJp8/3P/mOlwEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBtzznn0CADgOF4GACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACDuDsbUF9VUxk6jAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rain down\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABuCAYAAAC6LhD6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACOElEQVR4nO3YsU3DUBhGUYxYJhUSYoeM4ColAzAJA1Cm8gjsECFRMc5Lk94pwC7uOfUv65Nec+VpjDEeAICsx70HAAD7EgMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIe7r3cHo5/ecObsb3efXm/fNngyV8vD2v3niL7dzzHsuybLCEeZ5Xb46X3w2W8PV6+JPv+DMAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHHTGGPsPQIA2I8/AwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQdwV9rBfVKkWYTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spring\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABuCAYAAAC6LhD6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACLUlEQVR4nO3YsW0CQRBAUQ7RwMlN0Ihz9+ICEAW4F+c0QhPoSlgS5xDAnaX/XjxajTTJ105jjLEDALL2Wy8AAGxLDABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACDu8Ozg7fv0zj348/FzfjjjFutwi//lmXtcfy8rbMLx6/PhzLIsK2zCPM8vecfPAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADETWOMsfUSAMB2/AwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQNwd/xEX1WQ0ywcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summer\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABuCAYAAAC6LhD6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACMklEQVR4nO3YsU0DQRBAUZ9xB67AITkVkFAQBVgU4IJIqICckAooAa0T8rvAvkP678Wj1UiTfO00xhg7ACBrv/UCAMC2xAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADiDksHf17P99yDP8fL2+yMW6zDLf6XJfd4+fxaYRPenx5nZ75/n1fYhNPDx03e8TMAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHHTGGNsvQQAsB0/AwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQdwWLwhfVc5ccPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autumn\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABuCAYAAAC6LhD6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACPUlEQVR4nO3YoU0FQRhG0XkERQ8kKBTJNkADdIGgLARd0AANbIJCkdADdjD4fQJ2xT1H/9l8yZibPc055wAAsi6OHgAAHEsMAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIO7y3MNlWf5zB7/Wdd28+Xq82mEJ1y/fmzefz3c7LGGMMW6e3jdvvMc+znmLj9f7HZZw+/D2J9/xZwAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4k5zznn0CADgOP4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAEDcD8X6F9UjY4DPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winter\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABuCAYAAAC6LhD6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACMklEQVR4nO3cMW3EQABFwXV0BIwkcIwgAIIkAILAcILEEDZN+nNxsYs3U6+sL23ztIWXOeccAEDW290DAIB7iQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEPc4eXJblP3fw58wPIT+/fy5YwtfH+9Mz+75fsIQxxti27ekZ93GNM3dxHMcFS1jX9SXf8TIAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHHLnHPePQIAuI+XAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCI+wUhUxfVR2D8dQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Config_sample = Config\n",
    "Config_sample = Config.copy()\n",
    "Config_sample['Batch_Size'] = 1\n",
    "Config_sample['Mask_position'] = [0,1,2,3,4]   # mask all palette colors\n",
    "Config_sample['Text_Input_Emb_File_Path'] = f\"{sample_data_path}/{text_object}_emb_clip_{dataType}.txt\"\n",
    "\n",
    "for sample_id in range(len(sample_texts)):\n",
    "    dataset = DataGenerator(Config_sample)\n",
    "    batch_x,  batch_mlm_mask, batch_mcc_mask, origin_x, batch_segment, batch_padding_mask, batch_text_input_embed = dataset[sample_id]\n",
    "    mlm_predict, output_emb = re_model((batch_x, batch_mlm_mask, batch_segment, batch_text_input_embed), training=False)\n",
    "\n",
    "    palette = []\n",
    "    for pos in Config_sample['Mask_position']:\n",
    "        classes = np.argsort(mlm_predict[0][pos])\n",
    "        new_color = dataset.corpus.token_id_to_word_list(list(classes[::-1][:1]))\n",
    "        for c in new_color:\n",
    "            lab = c.split('_')\n",
    "            bin_range = Config_sample['bin_range']\n",
    "            rgb = range0to255(lab_to_rgb([int(lab[0])*bin_range, int(lab[1])*bin_range, int(lab[2])*bin_range]))\n",
    "            palette.append(rgb)\n",
    "\n",
    "    print(sample_texts[sample_id])\n",
    "    draw_palette(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
