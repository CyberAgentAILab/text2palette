{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the color_text dataset for multimodal color masked model input\n",
    "- Represent color with bins (bin_range = 16 <16bins> vocabulary max 4096; bin_range = 32 <8bins> vocabulary max 512)\n",
    "    - Format: color palette for image (max 5 colors)\n",
    "- Represent text with pre-trained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 02:23:16.562164: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict  # For word frequency\n",
    "import math\n",
    "import random\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from color_palette_completion.utils.text_emb_creator import save_text_embedding_clip\n",
    "from color_palette_completion.text_color_model.model_config import Config\n",
    "\n",
    "representation = Config['representation']\n",
    "bin_range = Config['bin_range']\n",
    "max_text_seq_length = {\n",
    "    'text_contents': Config['Max_Text_Contents_Length'],\n",
    "    'image_labels': Config['Max_Image_Labels_Length']\n",
    "}\n",
    "\n",
    "clusterMode = 'lab_' # training data created by lab color space or rgb\n",
    "kmeansType = '_sklearn'\n",
    "langType = '_en'\n",
    "dataTypes = ['train', 'val', 'test']\n",
    "textTypes = ['text_contents', 'image_labels']\n",
    "\n",
    "rawdata_path = '../data/colors'\n",
    "color_data_path = '../data/t2p/color'\n",
    "text_data_path = '../data/t2p/text'\n",
    "\n",
    "text_model = '_clip'\n",
    "emb_file = 'emb_clip_imagemust_seq'\n",
    "\n",
    "# Check if directory exists\n",
    "if not os.path.exists(color_data_path):\n",
    "    os.makedirs(color_data_path)\n",
    "    \n",
    "if not os.path.exists(text_data_path):\n",
    "    os.makedirs(text_data_path)\n",
    "    \n",
    "if not os.path.exists(f'{text_data_path}/{emb_file}'):\n",
    "    os.makedirs(f'{text_data_path}/{emb_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_list_bins(data, column_names):\n",
    "    color_hist = ''\n",
    "    for column in column_names:\n",
    "        if pd.notna(data[column]):\n",
    "            colors = ast.literal_eval(data[column])\n",
    "            for color in colors:\n",
    "                if color_hist != '':\n",
    "                    color_hist += ' '\n",
    "                color_hist += f'{math.floor(color[0]/bin_range)}_{math.floor(color[1]/bin_range)}_{math.floor(color[2]/bin_range)}'\n",
    "    return color_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['image_colors_lab_reorder', 'svg_colors_lab_reorder', 'text_colors_lab_reorder']\n",
    "\n",
    "def get_color_metadata(data, representation):\n",
    "\n",
    "    for column in column_names:\n",
    "        data[f'{column}'] = data.apply(lambda x: get_color_list_bins(x, [column]), axis=1)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def get_color_hist(data, column_names):\n",
    "    color_hist = ''\n",
    "    color_hist += f'{data[column_names[0]]} ; {data[column_names[1]]} ; {data[column_names[2]]}'\n",
    "\n",
    "    return color_hist\n",
    "\n",
    "def create_colordata(file_path, representation):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    metadata = get_color_metadata(data, representation)\n",
    "    metadata['color_hist'] = metadata.apply(lambda x: get_color_hist(x, column_names), axis=1)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create color corpus and text data: train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: DtypeWarning: Columns (242,244,246,248,282,284,286,288,290,326,328,330,332,334,336,338,340,342,344,346,348,350,352,382,384,386,388,390,392,394,396,398,400,402,404,406,408,410,412,414,416,418,420,422,424,426,428,430,432,434,436,438,440,442,444,446,448,450,452,454,456,458,460,462,464,466,468,470,472,474,476,478,480,482,484,486,488,490,492,494,496,498,500,502,504,506,508,510,512,514,516,518,520,522,524,526,528,530,532,534,536,538,540,542,544,546,548,550,552,554,556,558,560,562,564,566,568,570,572,574,576,578,580,582,584,586,588,590,592,594,596,598,600,602,604,606,608,610,612,614,616,618,620,622,624,626,628,630,632,634,636,638,640,642,644,646,648,650,652,654,656,658,660,662,664,666,668,670,672,674,676,678,680,682,684,686,688,690,692,694,696,698,700,702,704,706,708,710,712,714,716,718,720,722,724,726,728,730,732,734,736,738,740,742,744,746,748,750,752,754,756,758,760,762,764,766,768,770,772,774,776,778,780,782,784,786,788,790,792,794,796,798,800,802,804,806,808,810,812,814,816,818,820,822,824,826,828,830,832,834,836,838,840,842,844,846,848,850,852,854,856,858,860,862,864,866,868,870,872,874,876,878,880,882,884,886,888,890,892,894,896,898,900,902,904,906,908,910,912,914,916,918,920,922,924,926,928,930,932,934,936,938,940,942,944,946,948,950,952,954,956,958,960,962,964,966,968,970,972,974,976,978,980,982,984,986,988,990,992,994,996,998,1000,1002,1004,1006,1008,1010,1012,1014,1016,1018,1020,1022,1024,1026,1028,1030,1032,1034,1036,1038,1040,1042,1044,1046,1048,1050,1052,1054,1056,1058,1060,1062,1064,1066,1068,1070,1072,1074,1076,1078,1080,1082,1084,1086,1088,1090,1092,1094,1096,1098,1100,1102,1104,1106,1108,1110,1112,1114,1116,1118,1120,1122,1124,1126,1128,1130,1132,1134,1136,1138,1140,1142,1144,1146,1148,1150,1152,1154,1156,1158,1160,1162,1164,1166,1168,1170,1172,1174,1176,1178,1180,1182,1184,1186,1188,1190,1192,1194,1196,1198,1200,1202,1204,1206,1208,1210,1212,1214,1216,1218,1220,1222,1224,1226,1228,1230,1232,1234,1236,1238,1240,1242,1244,1246,1248,1250,1252,1254,1256,1258,1260,1262,1266,1268,1270,1272,1274,1276,1292,1294,1296,1298,1300,1302,1304,1306,1308,1310,1312,1314,1316,1318,1320,1322,1324,1326,1328,1330,1332,1334,1336,1338,1340,1342,1344,1346,1348,1350,1352,1368,1370,1372,1374,1376,1378,1380,1382,1384,1386,1388,1390,1392,1394,1396,1398,1400,1402,1404,1406,1408,1410,1412,1414,1416,1418,1420,1422,1424,1426,1428,1430,1432,1434,1436,1438,1440,1442,1444,1446,1448,1450,1452,1454,1456,1458,1460,1462,1464,1466,1468,1470,1472,1474,1476,1478,1480,1482,1484,1486,1488,1490,1492,1494,1496,1498,1500,1502,1504,1506,1508,1510,1512,1514,1516,1518,1520,1522,1524,1526,1528,1530,1532,1534,1536,1538,1540,1542,1544,1546,1548,1550,1552,1554,1556,1558) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14020, 1567)\n",
      "color freq size: 758\n",
      "color vocab size: 758\n",
      "val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: DtypeWarning: Columns (288,290,354,390,392,394,396,398,400,402,404,406,408,410,412,414,416,444,446,448,450,452,454,456,458,460,462,464,466,468,470,472,474,476,478,480,482,484,486,488,490,492,494,496,498,500,502,504,506,508,510,512,514,516,518,520,522,524,526,528,530,532,534,536,538,540,542,544,546,548,550,552,554,556,558,560,562,564,566,568,570,572,574,576,578,580,582,584,586,588,590,592,594,596,598,600,602,716,718,720) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1704, 729)\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: DtypeWarning: Columns (298,300,302,458,460,462,464,466,468,470,472,474,476,478,480,482,484,486,488,546,548,576,578,580,582,584,586,588,610,612,614,616,618,620,622,624,626,628,630,632,634,636,638,640) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1712, 659)\n"
     ]
    }
   ],
   "source": [
    "for dataType in dataTypes:\n",
    "    print(dataType)\n",
    "    metadata = create_colordata(f'{rawdata_path}/data_colors_labels/crello_labels_palette_{dataType}{kmeansType}_hfreqlabels_imagemust{langType}.csv', representation)\n",
    "    print(metadata.shape)\n",
    "\n",
    "    # create color data\n",
    "    metadata['color_hist'].to_csv(f'{color_data_path}/color_corpus_{representation}_{dataType}{kmeansType}.txt', header=None, index=None, sep=' ')\n",
    "    # create color vocab from train data\n",
    "    if dataType == 'train':\n",
    "        metadata_color_hist = pd.read_csv(f'{color_data_path}/color_corpus_{representation}_{dataType}{kmeansType}.txt', header=None)\n",
    "\n",
    "        # create sentences\n",
    "        sentences = [row.split(' ') for row in metadata['color_hist']]\n",
    "        color_freq = defaultdict(int)\n",
    "        for sent in sentences:\n",
    "            for i in sent:\n",
    "                color_freq[i] += 1\n",
    "        color_freq.pop(';')\n",
    "        print(f'color freq size: {len(color_freq)}')\n",
    "        colors = [a for a in color_freq]\n",
    "        # colors.remove('\\n')\n",
    "        print(f'color vocab size: {len(colors)}')\n",
    "        with open(f'{color_data_path}/color_vocab_{representation}_{dataType}{kmeansType}.txt', 'w') as f:\n",
    "            f.write(\"[\")\n",
    "            for i in range(len(colors)):\n",
    "                f.write(\"'%s',\" % colors[i]) if i != len(colors) - 1 else f.write(\"'%s'\" % colors[i])\n",
    "            f.write(\"]\")\n",
    "\n",
    "    # create text data\n",
    "    for textType in textTypes:\n",
    "        metadata[textType].to_csv(f'{text_data_path}/{textType}_imagemust_{dataType}{langType}.txt', header=None, index=None, sep=' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create text embedding for text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create text embedding and save\n",
    "def make_and_parse_text(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        texts_ = f.readlines()\n",
    "    for line in texts_:\n",
    "        yield line\n",
    "\n",
    "def make_text_data(file_path, dataType, textType):\n",
    "    text_input = []\n",
    "    \n",
    "    text_input_ = make_and_parse_text(file_path)\n",
    "    for tc in text_input_:\n",
    "        contents = tc.strip('[]\"\\n').split(',')\n",
    "\n",
    "        # separate each phrase as 1 text content\n",
    "        contents = [c.replace('\\'', '').replace('\\\\n', '. ') for c in contents] # use '.' between sentences of different lines\n",
    "        text_input.append(contents)\n",
    "        \n",
    "    data_path = f\"{text_data_path}/{emb_file}\"\n",
    "    print(f'start build {dataType} text contents embedding: {datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S\")}')\n",
    "    text_contents_emb = save_text_embedding_clip(text_input, data_path, textType, dataType, max_text_seq_length[textType])\n",
    "    print(f'finish build {dataType} text contents embedding: {datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S\")}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for dataType in dataTypes:\n",
    "        file_path = f'{text_data_path}/text_contents_imagemust_{dataType}{langType}.txt'\n",
    "        make_text_data(file_path, dataType, 'text_contents') # for seq text embedding building\n",
    "    for dataType in dataTypes:\n",
    "        file_path = f'{text_data_path}/image_labels_imagemust_{dataType}{langType}.txt'\n",
    "        make_text_data(file_path, dataType, 'image_labels') # for seq text embedding building\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17120, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the created embedding file\n",
    "text_input_emb_ = np.loadtxt(f'{text_data_path}/{emb_file}/image_labels_hfreq_emb{text_model}_test{langType}.txt', dtype=float)\n",
    "text_input_emb_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
