{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the pre-training of text-aware masked color model for color palette completion\n",
    "- It takes 50mins on GPU (Tesla T4 * 1) for one time training with early stop (patience=30)\n",
    "- For a quick start, do Pretraining with pre-created color corpus files and text embedding files\n",
    "    - To create color and text data for training, please check preprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-29 06:25:58.095672: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-29 06:26:00.034805: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2023-09-29 06:26:00.667292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-29 06:26:00.667954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-09-29 06:26:00.667995: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-09-29 06:26:00.677587: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\n",
      "2023-09-29 06:26:00.679843: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-09-29 06:26:00.682347: I tensorflow/stream_executor/platform/default"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-09-29 06:26:00.690920: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-09-29 06:26:00.692408: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-09-29 06:26:00.693314: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-09-29 06:26:00.693444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-29 06:26:00.694227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-29 06:26:00.694781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict  # For word frequency\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import color_palette_completion.text_color_model.color_model as Model\n",
    "from color_palette_completion.text_color_model.input_data_generator import DataGenerator\n",
    "from color_palette_completion.text_color_model.model_config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pretrain_task_accuracy(mlm_predict, batch_mlm_mask, origin_x):\n",
    "    \n",
    "    batch_mlm_mask = tf.cast(batch_mlm_mask, dtype=tf.int32)\n",
    "    index = tf.where(batch_mlm_mask == 1)\n",
    "    x_predict = tf.math.argmax(mlm_predict, axis=-1)\n",
    "    x_predict = tf.gather_nd(x_predict, index)\n",
    "    x_real = tf.gather_nd(origin_x, index)\n",
    "    mlm_accuracy = tf.keras.metrics.Accuracy()\n",
    "    mlm_accuracy.update_state(x_predict, x_real)\n",
    "    mlm_accuracy = mlm_accuracy.result().numpy()\n",
    "\n",
    "    return mlm_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-29 06:26:46.254903: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199995000 Hz\n",
      "2023-09-29 06:26:46.255638: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e304465560 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-29 06:26:46.255667: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-09-29 06:26:46.354601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-29 06:26:46.355390: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e305581640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-29 06:26:46.355421: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2023-09-29 06:26:46.355740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-29 06:26:46.356554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-09-29 06:26:46.356653: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-09-29 06:26:46.356692: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\n",
      "2023-09-29 06:26:46.356711: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-09-29 06:26:46.356728: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-09-29 06:26:46.356746: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-09-29 06:26:46.356763: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-09-29 06:26:46.356781: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-09-29 06:26:46.356884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-29 06:26:46.357601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-29 06:26:46.358183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-09-29 06:26:46.358243: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-09-29 06:26:46.820776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-09-29 06:26:46.820819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2023-09-29 06:26:46.820830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2023-09-29 06:26:46.821115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-29 06:26:46.821905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-29 06:26:46.822590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13996 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer text2_palettes is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-29 06:28:41.141051: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer text2_palettes__loss is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 0, step 15, loss 1.7074, mlm_loss 1.7074, mlm_acc 0.1689\n",
      "Val: Epoch 0, step 1, loss 1.7433, mlm_loss 1.7433, mlm_acc 0.1831\n",
      "Epoch 10, step 15, loss 1.4053, mlm_loss 1.4053, mlm_acc 0.2564\n",
      "Val: Epoch 10, step 1, loss 1.2969, mlm_loss 1.2969, mlm_acc 0.2735\n",
      "Epoch 20, step 15, loss 1.2231, mlm_loss 1.2231, mlm_acc 0.3307\n",
      "Val: Epoch 20, step 1, loss 1.2067, mlm_loss 1.2067, mlm_acc 0.3261\n",
      "Epoch 30, step 15, loss 1.0874, mlm_loss 1.0874, mlm_acc 0.3146\n",
      "Val: Epoch 30, step 1, loss 1.2477, mlm_loss 1.2477, mlm_acc 0.3245\n",
      "Epoch 40, step 15, loss 1.1058, mlm_loss 1.1058, mlm_acc 0.3698\n",
      "Val: Epoch 40, step 1, loss 1.1427, mlm_loss 1.1427, mlm_acc 0.3675\n",
      "Epoch 50, step 15, loss 1.0422, mlm_loss 1.0422, mlm_acc 0.3514\n",
      "Val: Epoch 50, step 1, loss 1.0880, mlm_loss 1.0880, mlm_acc 0.3420\n",
      "Epoch 60, step 15, loss 0.9803, mlm_loss 0.9803, mlm_acc 0.3837\n",
      "Val: Epoch 60, step 1, loss 1.0926, mlm_loss 1.0926, mlm_acc 0.3741\n",
      "Epoch 70, step 15, loss 0.9474, mlm_loss 0.9474, mlm_acc 0.3991\n",
      "Val: Epoch 70, step 1, loss 1.0855, mlm_loss 1.0855, mlm_acc 0.3929\n",
      "Epoch 80, step 15, loss 0.9647, mlm_loss 0.9647, mlm_acc 0.4192\n",
      "Val: Epoch 80, step 1, loss 1.0803, mlm_loss 1.0803, mlm_acc 0.3897\n",
      "Epoch 90, step 15, loss 0.9292, mlm_loss 0.9292, mlm_acc 0.4417\n",
      "Val: Epoch 90, step 1, loss 1.1011, mlm_loss 1.1011, mlm_acc 0.3854\n",
      "Epoch 100, step 15, loss 0.9049, mlm_loss 0.9049, mlm_acc 0.4236\n",
      "Val: Epoch 100, step 1, loss 1.0871, mlm_loss 1.0871, mlm_acc 0.3998\n",
      "Epoch 110, step 15, loss 0.9033, mlm_loss 0.9033, mlm_acc 0.4529\n",
      "Val: Epoch 110, step 1, loss 1.0041, mlm_loss 1.0041, mlm_acc 0.4215\n",
      "Epoch 120, step 15, loss 0.8886, mlm_loss 0.8886, mlm_acc 0.4526\n",
      "Val: Epoch 120, step 1, loss 1.0281, mlm_loss 1.0281, mlm_acc 0.4071\n",
      "Epoch 130, step 15, loss 0.8334, mlm_loss 0.8334, mlm_acc 0.4722\n",
      "Val: Epoch 130, step 1, loss 1.0288, mlm_loss 1.0288, mlm_acc 0.4067\n",
      "Epoch 140, step 15, loss 0.7847, mlm_loss 0.7847, mlm_acc 0.4837\n",
      "Val: Epoch 140, step 1, loss 1.0309, mlm_loss 1.0309, mlm_acc 0.3998\n",
      "Test: Epoch 147, step 1, loss 1.0710, mlm_loss 1.0710, mlm_acc 0.3969\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-29 07:10:16.008276: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/pretrained_model/t2p_ca1_mca1_i10t_stop30_lr0.0002__clip_512d_lab_bins_16_0.4_0.5_0/assets\n"
     ]
    }
   ],
   "source": [
    "# pretrain\n",
    "\n",
    "for n in range(1):\n",
    "    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "    assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "    # physical_devices = tf.config.experimental.list_physical_devices('CPU')\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "    model = Model.Text2Palettes(Config)\n",
    "    optimizer = tf.keras.optimizers.Adam(Config['Learning_Rate'])\n",
    "    loss_fn = Model.Text2Palettes_Loss()\n",
    "    dataset = DataGenerator(Config)\n",
    "\n",
    "    # create the data for validation and test\n",
    "    PROJECT_PATH = Config['project_path']\n",
    "    representation = Config['representation']\n",
    "    text_model = Config['text_model']\n",
    "    emb_file = Config['emb_file']\n",
    "    db_tag = Config['db_tag']\n",
    "    langType = Config['langType']\n",
    "    kmeansType = Config['kmeansType']\n",
    "\n",
    "    Config_val = Config.copy()\n",
    "    Config_val['Corpus_File_Path'] = os.path.join(PROJECT_PATH, f'Data_color/color_corpus_{representation}_val{kmeansType}.txt')\n",
    "    Config_val['Text_Contents_File_Path'] = os.path.join(PROJECT_PATH, f'Data_text/text_contents{db_tag}_val{langType}.txt')\n",
    "    Config_val['Image_Labels_File_Path'] = os.path.join(PROJECT_PATH, f'Data_text/image_labels{db_tag}_val{langType}.txt')\n",
    "    Config_val['Text_Contents_Emb_File_Path'] = os.path.join(PROJECT_PATH, f'Data_text/{emb_file}/text_contents_emb{text_model}_val.txt')\n",
    "    Config_val['Image_Labels_Emb_File_Path'] = os.path.join(PROJECT_PATH, f'Data_text/{emb_file}/image_labels_emb{text_model}_val.txt')\n",
    "\n",
    "    Config_test = Config.copy()\n",
    "    Config_test['Corpus_File_Path'] = os.path.join(PROJECT_PATH, f'Data_color/color_corpus_{representation}_test{kmeansType}.txt')\n",
    "    Config_test['Text_Contents_File_Path'] = os.path.join(PROJECT_PATH, f'Data_text/text_contents{db_tag}_test{langType}.txt')\n",
    "    Config_test['Image_Labels_File_Path'] = os.path.join(PROJECT_PATH, f'Data_text/image_labels{db_tag}_test{langType}.txt')\n",
    "    Config_test['Text_Contents_Emb_File_Path'] = os.path.join(PROJECT_PATH, f'Data_text/{emb_file}/text_contents_emb{text_model}_test.txt')\n",
    "    Config_test['Image_Labels_Emb_File_Path'] = os.path.join(PROJECT_PATH, f'Data_text/{emb_file}/image_labels_emb{text_model}_test.txt')\n",
    "\n",
    "    dataset_val = DataGenerator(Config_val)\n",
    "    dataset_test = DataGenerator(Config_test)\n",
    "\n",
    "    patience = 30 # baseline:10\n",
    "    best = math.inf\n",
    "    wait = 0\n",
    "\n",
    "    Config['Saved_Weight'] = os.path.join(PROJECT_PATH, f'Saved_Weight{text_model}_{Config[\"Embedding_Size\"]}d_{representation}_{Config[\"Mask_Rate\"]}_{Config[\"Mask_Token_Rate\"]}_v{n}')\n",
    "    checkpoint = tf.train.Checkpoint(model=model)\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(Config['Saved_Weight']))\n",
    "    manager = tf.train.CheckpointManager(checkpoint, directory=Config['Saved_Weight'], max_to_keep=5)\n",
    "    log_dir = os.path.join(Config['Log_Dir'], datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "    writer = tf.summary.create_file_writer(log_dir)\n",
    "    \n",
    "    EPOCH = 2000 # 2000 for training\n",
    "    for epoch in range(EPOCH):\n",
    "        for step in range(len(dataset)):\n",
    "            batch_x, batch_mlm_mask, batch_mcc_mask, origin_x, batch_segment, batch_padding_mask, batch_text_contents_embed, batch_image_labels_embed = dataset[step]\n",
    "      \n",
    "            with tf.GradientTape() as t:\n",
    "                mlm_predict, sequence_output = model((batch_x, batch_mlm_mask, batch_segment, batch_text_contents_embed, batch_image_labels_embed), training=True)\n",
    "\n",
    "                mlm_loss = loss_fn((mlm_predict, batch_mlm_mask, origin_x))\n",
    "                mlm_loss = tf.reduce_mean(mlm_loss)\n",
    "\n",
    "                loss = mlm_loss\n",
    "\n",
    "            gradients = t.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "            mlm_acc = calculate_pretrain_task_accuracy(mlm_predict, batch_mlm_mask, origin_x)\n",
    "\n",
    "            if step == len(dataset) - 1 and epoch % 10 == 0:\n",
    "                print(\n",
    "                    'Epoch {}, step {}, loss {:.4f}, mlm_loss {:.4f}, mlm_acc {:.4f}'.format(\n",
    "                        epoch, step, loss.numpy(),\n",
    "                        mlm_loss.numpy(),\n",
    "                        mlm_acc,\n",
    "                        ))\n",
    "\n",
    "        for val_step in range(len(dataset_val)):\n",
    "            val_batch_x, val_batch_mlm_mask, val_batch_mcc_mask, val_origin_x, val_batch_segment, val_batch_padding_mask, val_batch_text_contents_embed, val_batch_image_labels_embed = dataset_val[val_step]\n",
    "\n",
    "            val_mlm_predict, val_sequence_output = model((val_batch_x, val_batch_mlm_mask, val_batch_segment, val_batch_text_contents_embed, val_batch_image_labels_embed), training=False)\n",
    "\n",
    "            val_mlm_loss = loss_fn((val_mlm_predict, val_batch_mlm_mask, val_origin_x))\n",
    "            val_mlm_loss = tf.reduce_mean(val_mlm_loss)\n",
    "            \n",
    "            val_mlm_acc = calculate_pretrain_task_accuracy(val_mlm_predict, val_batch_mlm_mask, val_origin_x)\n",
    "\n",
    "            val_loss = val_mlm_loss\n",
    "\n",
    "            if val_step == len(dataset_val) - 1 and epoch % 10 == 0:\n",
    "                print(\n",
    "                    'Val: Epoch {}, step {}, loss {:.4f}, mlm_loss {:.4f}, mlm_acc {:.4f}'.format(\n",
    "                        epoch, val_step, val_loss.numpy(),\n",
    "                        val_mlm_loss.numpy(),\n",
    "                        val_mlm_acc,\n",
    "                        ))\n",
    "        \n",
    "        path = manager.save(checkpoint_number=epoch)\n",
    "\n",
    "        # early stopping\n",
    "        wait += 1\n",
    "        if val_loss < best:\n",
    "            best = val_loss\n",
    "            wait = 0\n",
    "        if wait >= patience:\n",
    "            break\n",
    "                \n",
    "    for test_step in range(len(dataset_test)):\n",
    "        test_batch_x, test_batch_mlm_mask, test_batch_mcc_mask, test_origin_x, test_batch_segment, test_batch_padding_mask, test_batch_text_contents_embed, test_batch_image_labels_embed = dataset_test[test_step]\n",
    "           \n",
    "        test_mlm_predict, test_sequence_output = model((test_batch_x, test_batch_mlm_mask, test_batch_segment, test_batch_text_contents_embed, test_batch_image_labels_embed), training=False)\n",
    "\n",
    "        test_mlm_loss = loss_fn((test_mlm_predict, test_batch_mlm_mask, test_origin_x))\n",
    "        test_mlm_loss = tf.reduce_mean(test_mlm_loss)\n",
    "\n",
    "        test_mlm_acc = calculate_pretrain_task_accuracy(test_mlm_predict, test_batch_mlm_mask, test_origin_x)\n",
    "\n",
    "        test_loss = test_mlm_loss\n",
    "        \n",
    "        if test_step == len(dataset_test) - 1:\n",
    "            print(\n",
    "                'Test: Epoch {}, step {}, loss {:.4f}, mlm_loss {:.4f}, mlm_acc {:.4f}'.format(\n",
    "                    epoch, test_step, test_loss.numpy(),\n",
    "                    test_mlm_loss.numpy(),\n",
    "                    test_mlm_acc,\n",
    "                    ))\n",
    "\n",
    "    # save model\n",
    "    model.save(f'../data/trained_model/t2p_ca1_mca1_i10t_stop{patience}_lr{Config[\"Learning_Rate\"]}_{text_model}_{Config[\"Embedding_Size\"]}d_{representation}_{Config[\"Mask_Rate\"]}_{Config[\"Mask_Token_Rate\"]}_{n}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
