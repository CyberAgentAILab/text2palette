{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This a tutorial of color palette completion for graphic documents stored as json files.\n",
    "- Step1: Extract the color palettes and text from json file\n",
    "    - In this work:\n",
    "        - Color palettes are from Image-SVG-Text elements\n",
    "        - Text contains text contexts in design and image labels by Vision API object detection\n",
    "- Step2: Extract the text embedding from CLIP model\n",
    "- Step3: Mask the color positions and get the recommended colors based on text and unmasked colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 02:27:53.592623: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from operator import itemgetter, attrgetter\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Image as ipyImage\n",
    "from ipycanvas import Canvas\n",
    "from base64 import b64encode, b64decode\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from collections import defaultdict  # For word frequency\n",
    "import math\n",
    "import random\n",
    "import ast\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from color_palette_completion.utils.color_convertor import lab_to_rgb, rgb_to_lab, range0to255, imageRGBA2LAB\n",
    "from color_palette_completion.utils.image_label_detector import detect_labels\n",
    "from color_palette_completion.preprocess.color_extractor import get_colors\n",
    "from color_palette_completion.text_color_model.input_data_generator import DataGenerator\n",
    "from color_palette_completion.text_color_model.model_config import Config\n",
    "from color_palette_completion.utils.text_emb_creator import save_text_embedding_clip\n",
    "\n",
    "representation = Config['representation']\n",
    "bin_range = Config['bin_range']\n",
    "\n",
    "# reset the sample url to check different samples\n",
    "sample_path = '../data/samples'\n",
    "sample_url = f'{sample_path}/crello_json/276.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step1: extract the color palettes and text from json file\n",
    "- Convert image data RGB to CIELab\n",
    "- Use Kmeans clustering in sklearn (kmeans in faiss can be faster, while the result is a little different)\n",
    "- Check the extracted colors by converting Lab to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape image as [w*h, 3] to concate multiple images\n",
    "def reshape_image(pil_image):\n",
    "    image = np.array(pil_image)\n",
    "    # remove the 4th channel of image\n",
    "    if len(image.shape) > 2 and image.shape[2] == 4:\n",
    "        #convert the image from RGBA2RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR) # Alpha channel may should be concerned in future work\n",
    "    image = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "    return image\n",
    "\n",
    "# draw palette without color rate\n",
    "def draw_palette(colors):\n",
    "    palette = np.zeros((50, 300, 3), dtype = \"uint8\")\n",
    "    startX = 0\n",
    "    for c in range(len(colors)):\n",
    "        endX = startX + (1 / len(colors) * 300)\n",
    "        cv2.rectangle(palette, (int(startX), 0), (int(endX), 50), colors[c], -1)\n",
    "        startX = endX\n",
    "    # draw border line for easy check in light gray #D3D3D3 \n",
    "    cv2.rectangle(palette, (0, 0), (300, 50), (211, 211, 211), 2)\n",
    "    plt.imshow(palette)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def draw_palettes(data_input, column_names):\n",
    "    for item, row in data_input.iterrows():\n",
    "        for cn in column_names:\n",
    "            if row[cn] == row[cn]: # string isNaN check\n",
    "                colors_lab = ast.literal_eval(row[cn])\n",
    "                colors = [lab_to_rgb(color) for color in colors_lab]\n",
    "                draw_palette(colors)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image palette:\n",
      "RGB data: [[182, 152, 151], [52, 47, 55], [212, 216, 223], [89, 106, 120], [141, 83, 65]]\n",
      "Lab data: [[167, 139, 133], [52, 132, 124], [220, 128, 124], [112, 125, 118], [106, 150, 149]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABmCAYAAABWfZKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADCElEQVR4nO3cwYuMYQDH8ecdq0VZFDkQaZVoV5IDuWjLSf5lN8mVaSNKRHLZgxlZuzPzuGouZqaZnuX3+Zyft36Xd/r29DZdrbUWACBWr/UAAKAtMQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBubdaD/X5/lTsAgBXY2tr66xk3AwAQbuabgT/5B2P4N3Vd13oCU/yeskqzvvNzx0CttQy+fCkHw8Hcozj6XrzaLR+/fms9gxXYefy43Nrebj2DKcPhsDx7/rKMxuPWU+L16qRcHnwqxyeHracsxdX7j8q5q5sznV3oZuBg8L383Ntb5FGOuHe7b8rr9x9az2AFbt+9V7reQq88K/TrsJa3Hz6X0WjUekq83mRcju31y4nxfuspS3Hx1p2Zz/pmAADCiQEACCcGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGuLPHT60qVy6vyFZW/hCHhy5lx5OPjRegYrcO36Zqmj/dYzmHL65LHydOdBqZNJ6ynxulLLxsHt0qvj1lOW4uzlazOfnTsGuq4r6xtn5n2Mf8SNCyLvv1ZHrRcwZf14r9zcvNJ6BuG6WmttPQIAaMc3AwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEO43CAtbjq+Xe/gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVG palette:\n",
      "RGB data: [[220, 38, 41], [19, 45, 81], [255, 255, 255]]\n",
      "Lab data: [[122, 195, 173], [47, 132, 103], [255, 128, 128]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABmCAYAAABWfZKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACuUlEQVR4nO3cParUUACG4ZPc+DPOtVAuiBYWgqAwK9DOXpfgIlyAuJm7gOsSLLV0Gn824IVRGDSVGmsLMROcOZHveeoT+JqBdw4hzTAMQwEAYrW1BwAAdYkBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcN3Yg+v1ep87AIA9WK1Wfz3jZgAAwo2+GfiNLxjDf80vmDGapqk9gQPZPQaGoXRnL0v74eMe5gCH8LZZlNPueu0ZzNiNk2vlxbOn5fKli7WnMNFmsyl93486O+lmoH33vhy9fjPlUWAGPrdXy6vuVin++fEHd27fLMvlcTleLmpPYaLtdjv6rHcGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAI10156PuTx+XHwwf/egtwIHebC+V5u6g9gxlbXlmU8/NP5Ut3VHsKE/V9P/rs7jHQNOXn/Xs7PwbMx0kp5VHtEcxe/+1r7QkcSDMMw1B7BABQj3cGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAg3C9aADRiYShGVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text palette:\n",
      "RGB data: [[255, 255, 255]]\n",
      "Lab data: [[255, 128, 128]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABmCAYAAABWfZKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACIUlEQVR4nO3aMW7CQBBAURPRQEHFMbj/STgGFFC43bTp4lhOHOm/V8/KU3559zDGGBMAkPWx9wIAwL7EAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAccelg/f7/Tf3AAB+we12+3bGnwEAiBMDABC3+Jrgq+v1Op1Op613AQA28nw+p3meF82uioHz+TxdLpc1RwGAP/B+vxfPuiYAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMQd1xx6PB7T6/XaehcAYCPzPC+eXRUDP/kAAPC/HcYYY+8lAID9eDMAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHGfHtsgRkloPyMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daeb0878e0bf4628b9c7ebd64fe806e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=315, sync_image_data=True, width=851)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load json file and show multiple palettes of Image-SVG-Text elements and the whole design image\n",
    "# save the color and text info into a temp file\n",
    "\n",
    "def line_break(text, height, font_size):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    lines = round(height / font_size)\n",
    "    words = text.split(' ')\n",
    "    lineWordNum = math.ceil(len(words) / lines)\n",
    "    newText = ''\n",
    "    idx = 0\n",
    "    for w in words:\n",
    "        newText += w\n",
    "        idx += 1\n",
    "        if idx % lineWordNum == 0:\n",
    "            newText += '\\n'\n",
    "        else:\n",
    "            newText += ' '            \n",
    "    return newText\n",
    "\n",
    "with open(sample_url) as json_file:\n",
    "    example = json.load(json_file)\n",
    "\n",
    "    columns = ['id', 'group', 'format', 'category', \n",
    "                'text_contents', 'image_labels',\n",
    "                'image_colors', 'svg_colors', 'text_colors',\n",
    "                'image_colors_lab', 'svg_colors_lab', 'text_colors_lab',\n",
    "                'image_colors_lab_reorder', 'svg_colors_lab_reorder', 'text_colors_lab_reorder']\n",
    "    df_text_palette = pd.DataFrame(columns = columns)\n",
    "    df_text_palette.at[0, 'id'] = example['id']\n",
    "    df_text_palette.at[0, 'group'] = example['group']\n",
    "    df_text_palette.at[0, 'format'] = example['format']\n",
    "    df_text_palette.at[0, 'category'] = example['category']\n",
    "\n",
    "    canvas_width = example['canvas_width']\n",
    "    canvas_height = example['canvas_height']\n",
    "    # draw all elements in canvas\n",
    "    canvas = Canvas(width=canvas_width, height=canvas_height, sync_image_data=True)\n",
    "\n",
    "    # initial image_list, svg_list, text_list\n",
    "    image_list = []\n",
    "    svg_list = []\n",
    "    text_list = []\n",
    "    text_size = []\n",
    "\n",
    "    # initial for text contents\n",
    "    text_contents = []\n",
    "    # initial for image contents detection (class)\n",
    "    image_labels = []\n",
    "    max_labels = 30\n",
    "\n",
    "    for i in range(len(example['types'])):\n",
    "        layer = example[f'element_{i}']\n",
    "        x = layer['left']*canvas_width\n",
    "        y = layer['top']*canvas_height\n",
    "        width = layer['width']*canvas_width\n",
    "        height = layer['height']*canvas_height\n",
    "        color_rgb = layer['color']\n",
    "        color_hex = '#%02x%02x%02x' % (color_rgb[0], color_rgb[1], color_rgb[2])\n",
    "\n",
    "        # reconstruct canvas to check\n",
    "        image = ipyImage.from_file(io.BytesIO(b64decode(layer['image_bytes'])))\n",
    "\n",
    "        if example['types'][i] == 'imageElement' or example['types'][i] == 'maskElement':\n",
    "            image_pil = Image.open(io.BytesIO(b64decode(layer['image_bytes'])))\n",
    "            image_list.append(reshape_image(imageRGBA2LAB(image_pil)))\n",
    "            # object detection for image\n",
    "            image_labels.append(detect_labels(b64decode(layer['image_bytes'])))\n",
    "            canvas.draw_image(image, x, y, width, height)    \n",
    "\n",
    "        if example['types'][i] == 'svgElement' or example['types'][i] == 'coloredBackground':\n",
    "            svg_pil = Image.open(io.BytesIO(b64decode(layer['image_bytes'])))\n",
    "            svg_list.append(reshape_image(imageRGBA2LAB(svg_pil)))\n",
    "            canvas.draw_image(image, x, y, width, height)    \n",
    "\n",
    "        if example['types'][i] == 'textElement':\n",
    "            if [color_rgb[0], color_rgb[1], color_rgb[2]] not in text_list:\n",
    "                text_list.append([color_rgb[0], color_rgb[1], color_rgb[2]])\n",
    "                text_size.append(width * height)\n",
    "\n",
    "            text = layer['text']\n",
    "            text_contents.append(layer['text'])\n",
    "            font = layer['font']\n",
    "            font_size = layer['font_size']\n",
    "            text_align = layer['text_align']\n",
    "            x = x + width if text_align == 'right' else x\n",
    "            x = x + width/2 if text_align == 'center' else x\n",
    "            angle = layer['angle']\n",
    "            \n",
    "            canvas.font = f'{font_size}px {font}'\n",
    "            color_rgb = layer['color']\n",
    "            color_hex = '#%02x%02x%02x' % (color_rgb[0], color_rgb[1], color_rgb[2])\n",
    "            canvas.stroke_style = color_hex\n",
    "            canvas.fill_style = color_hex\n",
    "            canvas.rotate = angle / math.pi * 180\n",
    "            canvas.text_align = text_align\n",
    "            text = line_break(text, height, font_size)\n",
    "            texts = text.split('\\n')\n",
    "            for t in range(len(texts)):\n",
    "                canvas.fill_text(texts[t], x, y+font_size*(t+1), max_width = width)\n",
    "                time.sleep(2) # sleep more time when text can not be fully stored\n",
    "                \n",
    "    for i in range(len(image_list)):\n",
    "        if i == 0:\n",
    "            image_np = image_list[i]\n",
    "        else:\n",
    "            image_np = np.concatenate((image_np, image_list[i]), axis=0)\n",
    "\n",
    "    for i in range(len(svg_list)):\n",
    "        if i == 0:\n",
    "            svg_np = svg_list[i]\n",
    "        else:\n",
    "            svg_np = np.concatenate((svg_np, svg_list[i]), axis=0)\n",
    "\n",
    "    # sort text color list by text area size\n",
    "    text_list = [x for _, x in sorted(zip(text_size, text_list), reverse=True)]\n",
    "    if len(text_list) > 5:\n",
    "        text_np = np.array(text_list)\n",
    "        (text_colors, text_colors_lab, text_color_rates, text_palette) = get_colors(text_np, 5)\n",
    "    else:\n",
    "        text_colors = text_list\n",
    "        text_colors_lab = [rgb_to_lab(rgb) for rgb in text_list]\n",
    "\n",
    "    if len(image_list) > 0:\n",
    "        (image_colors, image_colors_lab, image_color_rates, image_palette) = get_colors(image_np, 5)\n",
    "        df_text_palette.at[0, 'image_colors'] = image_colors\n",
    "        df_text_palette.at[0, 'image_colors_lab'] = image_colors_lab\n",
    "        image_colors_lab_reorder = image_colors_lab.copy()\n",
    "        image_colors_lab_reorder.sort(key=lambda x: x[0], reverse=False) # sort by lightness increasing\n",
    "        df_text_palette.at[0, 'image_colors_lab_reorder'] = image_colors_lab_reorder\n",
    "\n",
    "    if len(svg_list) > 0:\n",
    "        (svg_colors, svg_colors_lab, svg_color_rates, svg_palette) = get_colors(svg_np, 5)\n",
    "        df_text_palette.at[0, 'svg_colors'] = svg_colors\n",
    "        df_text_palette.at[0, 'svg_colors_lab'] = svg_colors_lab\n",
    "        svg_colors_lab_reorder = svg_colors_lab.copy()\n",
    "        svg_colors_lab_reorder.sort(key=lambda x: x[0], reverse=False) # sort by lightness increasing\n",
    "        df_text_palette.at[0, 'svg_colors_lab_reorder'] = svg_colors_lab_reorder\n",
    "    \n",
    "    if len(text_list) > 0:\n",
    "        df_text_palette.at[0, 'text_colors'] = text_colors\n",
    "        df_text_palette.at[0, 'text_colors_lab'] = text_colors_lab\n",
    "        text_colors_lab_reorder = text_colors_lab.copy()\n",
    "        text_colors_lab_reorder.sort(key=lambda x: x[0], reverse=False) # sort by lightness increasing\n",
    "        df_text_palette.at[0, 'text_colors_lab_reorder'] = text_colors_lab_reorder\n",
    "\n",
    "    if texts:\n",
    "        df_text_palette.at[0, f'text_contents'] = text_contents\n",
    "    \n",
    "    label_list = []\n",
    "    for i in range(len(image_labels)):\n",
    "        top_labels_i = image_labels[i]\n",
    "        for l in range(min(len(top_labels_i), Config['Max_Image_Labels_Length'])):\n",
    "            label_list.append(top_labels_i[l].description)\n",
    "    df_text_palette.at[0, f'image_labels'] = label_list\n",
    "\n",
    "    df_text_palette.to_csv(f'{sample_path}/colors/text_palette.csv', index = False, header=True)\n",
    "\n",
    "    print('Image palette:')\n",
    "    print(f'RGB data: {image_colors}')\n",
    "    print(f'Lab data: {image_colors_lab}')\n",
    "    plt.imshow(image_palette)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    print('SVG palette:')\n",
    "    print(f'RGB data: {svg_colors}')\n",
    "    print(f'Lab data: {svg_colors_lab}')\n",
    "    plt.imshow(svg_palette)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    print('Text palette:')\n",
    "    print(f'RGB data: {text_colors}')\n",
    "    print(f'Lab data: {text_colors_lab}')\n",
    "    draw_palette(text_colors)\n",
    "\n",
    "canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the color-text info to new input -> Here is a sample of changing 1 image\n",
    "# 2 input cases are offered in this tutorial\n",
    "# save the color and text info in a temp file\n",
    "\n",
    "# new input case1\n",
    "# image_input = f'{sample_path}/images/145.png'\n",
    "# text_contents_input = ['International Day of Forests', 'Joint celebration & forest cleanup special event']\n",
    "\n",
    "# new input case2\n",
    "image_input = f'{sample_path}/images/2045.png'\n",
    "text_contents_input = ['Wedding party', 'How to prepare']\n",
    "\n",
    "rawdata = pd.read_csv(f'{sample_path}/colors/text_palette.csv')\n",
    "with Image.open(image_input) as img:\n",
    "    image_np = reshape_image(imageRGBA2LAB(img))\n",
    "    (image_colors, image_colors_lab, image_color_rates, image_palette) = get_colors(image_np, 5)\n",
    "    rawdata['image_colors'] = str(image_colors)\n",
    "    rawdata['image_colors_lab'] = str(image_colors_lab)\n",
    "    image_colors_lab_reorder = image_colors_lab.copy()\n",
    "    image_colors_lab_reorder.sort(key=lambda x: x[0], reverse=False) # sort by lightness increasing\n",
    "    rawdata['image_colors_lab_reorder'] = str(image_colors_lab_reorder)\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "    img.save(buffer, format=\"png\")\n",
    "    image_labels = detect_labels(buffer.getvalue())\n",
    "    label_list = []\n",
    "    for l in range(min(len(image_labels), Config['Max_Image_Labels_Length'])):\n",
    "        label_list.append(image_labels[l].description)\n",
    "    rawdata['image_labels'] = str(label_list)\n",
    "    rawdata['text_contents'] = str(text_contents_input)\n",
    "\n",
    "    rawdata.to_csv(f'{sample_path}/colors/text_palette_new.csv', index=None, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step2: Extract the text embedding from CLIP model\n",
    "- Save the embeddings in temp files for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_data_path = 't2p/color'\n",
    "text_data_path = 't2p/text'\n",
    "\n",
    "langType = '_en'\n",
    "\n",
    "text_model = '_clip'\n",
    "emb_file = 'emb_clip_seq'\n",
    "\n",
    "def get_color_list_bins(data, column_names):\n",
    "    color_hist = ''\n",
    "    for column in column_names:\n",
    "        if pd.notna(data[column]):\n",
    "            colors = ast.literal_eval(data[column])\n",
    "            for color in colors:\n",
    "                if color_hist != '':\n",
    "                    color_hist += ' '\n",
    "                color_hist += f'{math.floor(color[0]/bin_range)}_{math.floor(color[1]/bin_range)}_{math.floor(color[2]/bin_range)}'\n",
    "    return color_hist\n",
    "\n",
    "column_names = ['image_colors_lab_reorder', 'svg_colors_lab_reorder', 'text_colors_lab_reorder']\n",
    "\n",
    "def get_color_metadata(data, representation):\n",
    "\n",
    "    for column in column_names:\n",
    "        data[f'{column}'] = data.apply(lambda x: get_color_list_bins(x, [column]), axis=1)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def get_color_hist(data, column_names):\n",
    "    color_hist = ''\n",
    "    color_hist += f'{data[column_names[0]]} ; {data[column_names[1]]} ; {data[column_names[2]]}'\n",
    "\n",
    "    return color_hist\n",
    "\n",
    "def create_colordata(file_path, representation):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    metadata = get_color_metadata(data, representation)\n",
    "    metadata['color_hist'] = metadata.apply(lambda x: get_color_hist(x, column_names), axis=1)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = create_colordata(f'{sample_path}/colors/text_palette_new.csv', representation)\n",
    "metadata['color_hist'].to_csv(f'{sample_path}/t2p/color/color_corpus_pred.txt', header=None, index=None, sep=' ')\n",
    "metadata['text_contents'].to_csv(f'{sample_path}/t2p/text/text_contents.txt', header=None, index=None, sep=' ')\n",
    "metadata['image_labels'].to_csv(f'{sample_path}/t2p/text/image_labels.txt', header=None, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wedding party', 'How to prepare']\n",
      "start build sample text contents embedding: 2023-10-23-02:28:22\n",
      "../data/samples/t2p/text/emb_clip/text_contents_emb_clip_sample.txt has been removed successfully\n",
      "finish build sample text contents embedding: 2023-10-23-02:28:29\n",
      "['Food', 'Cake decorating', 'Cake decorating supply', 'Ingredient', 'Cake', 'Recipe', 'Cuisine', 'Baked goods', 'Cream', 'Baking cup']\n",
      "start build sample text contents embedding: 2023-10-23-02:28:29\n",
      "../data/samples/t2p/text/emb_clip/image_labels_emb_clip_sample.txt has been removed successfully\n",
      "finish build sample text contents embedding: 2023-10-23-02:28:34\n"
     ]
    }
   ],
   "source": [
    "text_columns = ['text_contents', 'image_labels']\n",
    "max_text_seq_length = {\n",
    "    'text_contents': Config['Max_Text_Contents_Length'],\n",
    "    'image_labels': Config['Max_Image_Labels_Length'],\n",
    "}\n",
    "\n",
    "for text_column in text_columns:\n",
    "    lines_as_lists = []\n",
    "\n",
    "    # open the file in read mode\n",
    "    with open(f'{sample_path}/t2p/text/{text_column}.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip().strip('\"')\n",
    "            try:\n",
    "                parsed_list = ast.literal_eval(line)\n",
    "                lines_as_lists.append(parsed_list)\n",
    "            except ValueError as e:\n",
    "                print(f\"Could not parse line: {line}. Error: {e}\")\n",
    "\n",
    "    # only deal with the first line text\n",
    "    print(lines_as_lists[0])\n",
    "    \n",
    "    # create and save text embeddings\n",
    "    dataType = 'sample'\n",
    "    sample_data_path = f'{sample_path}/t2p/text/emb_clip'\n",
    "    print(f'start build {dataType} text contents embedding: {datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S\")}')\n",
    "    text_contents_emb = save_text_embedding_clip(lines_as_lists[0], sample_data_path, text_column, dataType, max_text_seq_length[text_column])\n",
    "    print(f'finish build {dataType} text contents embedding: {datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step3: Mask the color positions and get the recommended colors based on text and unmasked colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 02:28:34.730103: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2023-10-23 02:28:34.730353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-23 02:28:34.732126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.56GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-10-23 02:28:34.732187: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-10-23 02:28:34.732261: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\n",
      "2023-10-23 02:28:34.733448: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-10-23 02:28:34.733822: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-10-23 02:28:34.736355: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-10-23 02:28:34.736963: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-10-23 02:28:34.737057: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-10-23 02:28:34.737192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-23 02:28:34.738799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-23 02:28:34.740277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-10-23 02:28:34.747476: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199995000 Hz\n",
      "2023-10-23 02:28:34.747731: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557a4ef6e7a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-23 02:28:34.747759: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-10-23 02:28:34.749665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-23 02:28:34.751212: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557a4ef6b460 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-23 02:28:34.751230: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2023-10-23 02:28:34.751460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-23 02:28:34.752963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.56GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-10-23 02:28:34.753032: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-10-23 02:28:34.753061: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\n",
      "2023-10-23 02:28:34.753087: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-10-23 02:28:34.753109: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-10-23 02:28:34.753133: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-10-23 02:28:34.753156: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-10-23 02:28:34.753177: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-10-23 02:28:34.753267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-23 02:28:34.754825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-23 02:28:34.756278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-10-23 02:28:34.756346: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-10-23 02:28:35.036693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-10-23 02:28:35.036736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2023-10-23 02:28:35.036745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2023-10-23 02:28:35.037074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-23 02:28:35.038826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-23 02:28:35.040369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12893 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "filename = f'../data/trained_model/t2p_ca1_mca1_i10t_stop30_lr0.0002__clip_512d_lab_bins_16_0.4_0.5_0'\n",
    "re_model = tf.keras.models.load_model(f\"{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image-SVG-Text palettes:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABmCAYAAABWfZKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAC00lEQVR4nO3czUpUcQDG4feMHzOZJZZGBbUWElpnt+Ddeg+tXLpJXEYXEARp1Gnhpp2OHxzrfR6Y3TnwwjCcH38OM4zjOAYAqDWbegAAMC0xAADlxAAAlBMDAFBODABAOTEAAOXEAACUEwMAUG71uheenJzc5w4A4B7s7+9feY2TAQAod+2Tgb/5B2O4NEw9AB6qwa/jX7J0DIzjmE9HR/l6dnYfe7jCMAz5+PR1nq0tpp5Cks2d7Tx6sjn1DJJkayPD7tbUK0iS9bXMdp5HLk/r+5hcXPPaG50MfDk9zefj45vcyi0NSd6/2MvW3APoIVh58yrz3e2pZ5Ak51uZbaxMvYIk+bXILA4HpvZjiUN87wwAQDkxAADlxAAAlBMDAFBODABAOTEAAOXEAACUEwMAUE4MAEA5MQAA5cQAAJQTAwBQTgwAQDkxAADlxAAAlBMDAFBODABAOTEAAOXEAACUEwMAUE4MAEA5MQAA5cQAAJQTAwBQTgwAQDkxAADlxAAAlBMDAFBODABAOTEAAOXEAACUEwMAUE4MAEA5MQAA5cQAAJQTAwBQTgwAQDkxAADlxAAAlBMDAFBODABAOTEAAOXEAACUEwMAUE4MAEA5MQAA5cQAAJQTAwBQTgwAQDkxAADlxAAAlBMDAFBODABAOTEAAOXEAACUEwMAUE4MAEA5MQAA5cQAAJQTAwBQTgwAQDkxAADlxAAAlBMDAFBODABAOTEAAOXEAACUEwMAUE4MAEA5MQAA5cQAAJQTAwBQTgwAQDkxAADlxAAAlBMDAFBu9SY3fTg8zLuDg7vewjUMSV4unmZ9dqOvjjt2sbHIt/n61DNIkvla8ngx9QqSDCsryZjLD5P5ucS1Sz9RhmHI2729ZW+D/9LvJOdTjwC4pWEcR+0GAMW8MwAA5cQAAJQTAwBQTgwAQDkxAADlxAAAlBMDAFBODABAOTEAAOX+AGVwLiIdRXSzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABmCAYAAABWfZKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACrklEQVR4nO3csWqTURzG4f+nBd0ydOviJg6xg07i5iJ4AQ4OentegJfQ0TGiIE6hY4RG+Iqt7XELxcUvoeEo7/PM58A7ZPhx+MjQWmsFAMS603sAANCXGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAh3MPXgYrHY5w4AYA/m8/lfz3gZAIBwk18GbvIPxvwrht4D4E+DXyX/n61joLVW7z+c1Odvp/vYA5O9+fW9jtt57xmwcf/pk5q9e9t7BlRV1Wq1qnEcJ53d6WXg09dlnXz8sstVuDUvL0/r7vWP3jNg497hYc1ms94zoKqq1uv15LO+GQCAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAIJwYAIJwYAIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMKJAQAIJwYAINzBLpdev3peL549vu0tsJWH1+d10S57z4CN9dFRXSyXvWdAVVWN4zj57NYxMAxDHT96sO012Iur3gPghquq+nl21nsGbG1orbXeIwCAfnwzAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4X4D9QdAvFfmkKgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABmCAYAAABWfZKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACIUlEQVR4nO3aMW7CQBBAURPRQEHFMbj/STgGFFC43bTp4lhOHOm/V8/KU3559zDGGBMAkPWx9wIAwL7EAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAccelg/f7/Tf3AAB+we12+3bGnwEAiBMDABC3+Jrgq+v1Op1Op613AQA28nw+p3meF82uioHz+TxdLpc1RwGAP/B+vxfPuiYAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMQd1xx6PB7T6/XaehcAYCPzPC+eXRUDP/kAAPC/HcYYY+8lAID9eDMAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHGfHtsgRkloPyMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommendation color for position: 6\n",
      "original color:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 02:28:42.708103: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABmCAYAAABWfZKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACTklEQVR4nO3cMWpbQRRA0f+DthFwGYywwVXAbgMugncQsjRvwStIkypliAgYd85CxlXAnb+EZAnuOfUbeOVlGGYeY4wJAMj6cOwFAIDjEgMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMStlg5uNptD7gEAHMB6vX5zxs0AAMQtvhl4zQ/GAHD65nleNLd1DIwxpvuHn9Ofp39bLwUAvI9vX6+nq/OzRbM73Qz8fnyefvz6u8tRAOAdfPn89luB/7wZAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADErXY59P3uZrq9vtj3LgDAnlx++rh4dusYmOd5ujo/2/YYAHCi5jHGOPYSAMDxeDMAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHEvMpgf7gXhVxIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommended color:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABmCAYAAABWfZKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACSElEQVR4nO3cMWpbQRRA0f8TYbyEqI2LYBBxHcgWQraadaRyoSa4cG3vIEQwbt3lfyFZhntO/QZeeRmGmccYYwIAsj5cegEA4LLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcZulg/v9/px7AABnsNvt/jvjZgAA4hbfDLzmB2MAeP/meV40tzoGxhjT31/30+HhefVSAMDbuP7xddrcbhfNHnUzcPjzNP37/XjMUQDgDVx9+7x41psBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAEDc5phD1z/vpqvvN6feBQA4kY9fPi2eXR0D8zxPm9vt2mMAwDs1jzHGpZcAAC7HmwEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiHsBIa0fCMwC/psAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommendation color for position: 7\n",
      "original color:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABmCAYAAABWfZKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACP0lEQVR4nO3cMUoDURRA0RnNTkQQTCdWgp224kLtXYKdTQqx0I1Ivq2dk6BGuOfU7zOvvHw+M48xxgQAZB0degEA4LDEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcaulg5vN5jf3AAB+wXq9/nbGzQAAxC2+GfjKH4wB4P+b53nR3M4xMMaYPh4ep+3r+85LAQB/Y3V3Mx2fny6b3ecD25e3afv0vM9RAOAPjKuLxbPeDABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4lZ7Hbq/ncb15U/vAgD8kKOzk8WzO8fAPM/T8fnprscAgH9qHmOMQy8BAByONwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAEPcJr7QhNTfn0wAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommended color:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABmCAYAAABWfZKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACM0lEQVR4nO3cO2oDMRRAUSkEYxMXXoj3vxIvJE0gH4hSp8rY5Af3nPo9UDcXIWautdYAALLu/voAAMDfEgMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMTdbx28XC4/eQ4A4Aecz+cvZ9wMAEDc5puBT/zBGAD+vzk3jV0fA2uN+fg05vPb1asAwO94Pz2Mcdhtmr3pZmA+v467p5dbVgGAX7CO+7H1Ht+bAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABA3P0tS++n41jHw3efBQD4Jmu/2zx7fQzMOcZhN9bViwDAfzTXWr7rABDmzQAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxH0AVoUfD6vBox8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_pred = pd.read_csv(f'{sample_path}/colors/text_palette_new.csv')\n",
    "\n",
    "# set mask positions\n",
    "# 1 denotes mask\n",
    "maskColors = {\n",
    "    'image': '[0,0,0,0,0]',\n",
    "    'svg': '[1,1,0]',\n",
    "    'text': '[0]',\n",
    "}\n",
    "volumns = ['image', 'svg', 'text']\n",
    "max_palette_length = Config['Max_Palette_Length']\n",
    "mask_positions = []\n",
    "position = 0\n",
    "for v in range(len(volumns)):\n",
    "    pi = 0\n",
    "    for m in ast.literal_eval(maskColors[volumns[v]]):\n",
    "        if m == 1:\n",
    "            mask_positions.append(position+pi)\n",
    "        pi +=1\n",
    "    position += max_palette_length[v] + 1  # add 1 position of SEP\n",
    "Config_pred = Config.copy()\n",
    "Config_pred['Batch_Size'] = 1\n",
    "Config_pred['Mask_position'] = mask_positions   # mask specified colors\n",
    "Config_pred['Corpus_File_Path'] = os.path.join(f'{sample_path}/t2p/color/color_corpus_pred.txt')\n",
    "Config_pred['Text_Contents_File_Path'] = os.path.join(f'{sample_path}/t2p/text/text_contents.txt')\n",
    "Config_pred['Image_Labels_File_Path'] = os.path.join(f'{sample_path}/t2p/text/image_labels.txt')\n",
    "Config_pred['Text_Contents_Emb_File_Path'] = os.path.join(f'{sample_path}/t2p/text/emb_clip/text_contents_emb_clip_sample.txt')\n",
    "Config_pred['Image_Labels_Emb_File_Path'] = os.path.join(f'{sample_path}/t2p/text/emb_clip/image_labels_emb_clip_sample.txt')\n",
    "\n",
    "column_names = ['image_colors_lab_reorder', 'svg_colors_lab_reorder', 'text_colors_lab_reorder']\n",
    "\n",
    "sample_id = 0\n",
    "print('Original Image-SVG-Text palettes:')\n",
    "draw_palettes(data_pred[sample_id:sample_id+1], column_names)\n",
    "\n",
    "dataset = DataGenerator(Config_pred)\n",
    "batch_x,  batch_mlm_mask, batch_mcc_mask, origin_x, batch_segment, batch_padding_mask, batch_text_contents_embed, batch_image_labels_embed = dataset[sample_id]\n",
    "\n",
    "mlm_predict, output_emb = re_model((batch_x, batch_mlm_mask, batch_segment, batch_text_contents_embed, batch_image_labels_embed), training=False)\n",
    "\n",
    "for pos in Config_pred['Mask_position']:\n",
    "    classes = np.argsort(mlm_predict[0][pos])\n",
    "    new_color = dataset.corpus.token_id_to_word_list(list(classes[::-1][:1]))\n",
    "    print(f'recommendation color for position: {pos}')\n",
    "    print(f'original color:')\n",
    "    c = dataset.corpus.token_id_to_word_list(list(origin_x[0]))[pos]\n",
    "    lab = c.split('_')\n",
    "    rgb = range0to255(lab_to_rgb([int(lab[0])*bin_range, int(lab[1])*bin_range, int(lab[2])*bin_range]))\n",
    "    draw_palette([rgb])\n",
    "    print(f'recommended color:')\n",
    "    for c in new_color:\n",
    "        lab = c.split('_')\n",
    "        rgb = range0to255(lab_to_rgb([int(lab[0])*bin_range, int(lab[1])*bin_range, int(lab[2])*bin_range]))\n",
    "        draw_palette([rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
